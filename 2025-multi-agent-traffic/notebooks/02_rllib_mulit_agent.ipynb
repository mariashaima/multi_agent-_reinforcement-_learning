{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from marl_traffic_gen.environments.envs import RLlibMultiAgentMetaDrive\n",
    "\n",
    "env = RLlibMultiAgentMetaDrive(\n",
    "    dict(\n",
    "        map=\"S\",\n",
    "        is_multi_agent=True,\n",
    "        force_reuse_object_name=True,\n",
    "        traffic_density=0.0,\n",
    "        num_agents=2,\n",
    "        allow_respawn=False,\n",
    "        random_agent_model=False,\n",
    "        crash_done=True,\n",
    "        out_of_road_done=True,\n",
    "        delay_done=25,\n",
    "        start_seed=42,\n",
    "        num_scenarios=1,\n",
    "        log_level=50,\n",
    "        horizon=1000,\n",
    "        interface_panel=[\"dashboard\"],\n",
    "        truncate_as_terminate=True,\n",
    "        out_of_road_penalty=5,\n",
    "        crash_vehicle_penalty=5,\n",
    "        crash_object_penalty=5,\n",
    "        crash_vehicle_cost=1,\n",
    "        crash_object_cost=1,\n",
    "        out_of_road_cost=2,\n",
    "        success_reward=10,\n",
    "        crash_sidewalk_penalty=2,\n",
    "        agent_configs={\n",
    "            \"agent0\": {\n",
    "                \"vehicle_model\": \"static_default\",\n",
    "                \"random_color\": False,\n",
    "                \"_specified_spawn_lane\": True,\n",
    "                \"spawn_longitude\": 40.0,\n",
    "                \"spawn_lateral\": 7.0,\n",
    "            },\n",
    "            \"agent1\": {\n",
    "                \"vehicle_model\": \"static_default\",\n",
    "                \"random_color\": False,\n",
    "                \"_specified_spawn_lane\": True,\n",
    "                \"spawn_longitude\": 15.0,\n",
    "                \"spawn_lateral\": 4.0,\n",
    "            },\n",
    "        },\n",
    "        # use_render=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run an episode\n",
    "obs, _ = env.reset(seed=42)\n",
    "print(\"MARL agent IDs:\", list(obs.keys()))\n",
    "print(\"------------------------\")\n",
    "for ob in obs:\n",
    "    print(f\"Observation for {ob}:\")\n",
    "    print(f\"{obs[ob]}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_COLOR = (153 / 255, 0 / 255, 0 / 255)\n",
    "GREY_COLOR = (128 / 255, 128 / 255, 128 / 255)\n",
    "\n",
    "\n",
    "def set_vehicle_color(env: RLlibMultiAgentMetaDrive, adv_agent_ids: list[int | str] = None) -> None:\n",
    "    # Default to empty list if no adversarial agent IDs are provided\n",
    "    if adv_agent_ids is None:\n",
    "        adv_agent_ids = []\n",
    "\n",
    "    for key, vehicle in env.env.engine.get_objects().items():\n",
    "        if key in adv_agent_ids:\n",
    "            vehicle._panda_color = RED_COLOR\n",
    "        else:\n",
    "            vehicle._panda_color = GREY_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_vehicle_color(env, adv_agent_ids=env.agents)\n",
    "\n",
    "topdown = env.env.render(\n",
    "    mode=\"topdown\",\n",
    "    window=False,\n",
    "    scaling=3,\n",
    "    screen_size=(600, 600),\n",
    "    camera_position=(80, 0),\n",
    ")\n",
    "\n",
    "# Display with matplotlib\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(topdown, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.utils.pre_checks.env import check_multiagent_environments\n",
    "\n",
    "print(hasattr(env, \"observation_space\"))\n",
    "print(hasattr(env, \"action_space\"))\n",
    "print(hasattr(env, \"_agent_ids\"))\n",
    "\n",
    "obs_and_infos = env.reset(seed=42, options={})\n",
    "print(obs_and_infos)\n",
    "\n",
    "check_multiagent_environments(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {agent_id: [0.0, 0.2] for agent_id in obs}\n",
    "\n",
    "env.step(actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
